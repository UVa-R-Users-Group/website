<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cville R users</title>
    <link>/</link>
    <description>Recent content on Cville R users</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018. All rights reserved.</copyright>
    <lastBuildDate>Thu, 12 Apr 2018 15:48:05 -0400</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Projects</title>
      <link>/projects/</link>
      <pubDate>Thu, 12 Apr 2018 15:48:05 -0400</pubDate>
      
      <guid>/projects/</guid>
      <description>A place to link to or describe fun projects, packages, research, or more!</description>
    </item>
    
    <item>
      <title>About CvilleRs</title>
      <link>/about/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>The Cville/UVa R meetup began in September 2014 as a the local R user group for the University of Virginia and Charlottesville area. Sponsored by the UVA Library&amp;rsquo;s Research Data Services, our goal is to support and share R experience and knowledge among users in the local community (and beyond).
We&amp;rsquo;re a collection of novices and experts, the universty-affilitated and community-focused, enthusiasts and researchers, and lifelong learners of many stripes. Come join us!</description>
    </item>
    
    <item>
      <title>Social Network Analysis</title>
      <link>/post/social-network-analysis/</link>
      <pubDate>Tue, 21 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/social-network-analysis/</guid>
      <description>This script, presented at the April 2015 Meetup, demonstrates how to carry out basic social network analysis (SNA) using the network and sna packages. Topics covered include preparing data for analysis, interpreting output, and generating social network graphs.
The script assumes no prior knowledge of SNA but does assume a basic working knowledge of R. Most code is commented with an explanation of its purpose.
After this demonstration, hopefully Meetup participants will have an understanding of how to begin and carry out a basic social network analysis in R.</description>
    </item>
    
    <item>
      <title>Heat Maps</title>
      <link>/post/heat-maps/</link>
      <pubDate>Thu, 19 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/heat-maps/</guid>
      <description>library(dplyr) # Data manipulation &amp;amp; magrittr pipe library(ggplot2) # General plotting library(NMF) # aheatmap() library(gplots) # heatmap.2() library(RColorBrewer) # Brewer palettes set.seed(123) ############################ # 2D histograms # ############################ # simulate data that consiststs of paired observations in two experiments covar_mat &amp;lt;- matrix(c(5, 4, 4, 5), ncol = 2) # Covariance matrix data &amp;lt;- MASS::mvrnorm(n = 10000, mu = c(0, 0), Sigma = covar_mat) %&amp;gt;% #Simulate correlated data rbind(matrix(rnorm(20000, sd = 0.</description>
    </item>
    
    <item>
      <title>caret: streamline the process of predictive modeling</title>
      <link>/post/caret-streamline-the-process-of-predictive-modeling/</link>
      <pubDate>Thu, 19 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/caret-streamline-the-process-of-predictive-modeling/</guid>
      <description>This demonstration of the caret package was given by Mark Lawson, bioinformatician at Hemoshear LLC, Charlottesville VA. The caret package (short for Classification And REgression Training) is a set of functions that streamline the process for creating predictive models. The package contains tools for data splitting, pre-processing, feature selection, model tuning using resampling, and variable importance estimation. Read more about the caret package here.
This demonstration uses the caret package to split data into training and testing sets, and run repeated cross-validation to train random forest and penalized logistic regression models for classifying Fisher’s iris data.</description>
    </item>
    
    <item>
      <title>Web Scraping</title>
      <link>/post/web-scraping/</link>
      <pubDate>Tue, 07 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/web-scraping/</guid>
      <description>Web Scraping Take data formatted for display in a web browser and reformat for analysis.
It helps to know…
 a little about HTML and XML how to manipulate strings in R a little something about regular expressions how to write a function and do some basic conditional looping  Web scraping is mostly cleaning data.
 Strategy Every web page is different, but a basic procedure in R (for a single web page) is as follows:</description>
    </item>
    
    <item>
      <title>Kickoff Meetup: dplyr demo</title>
      <link>/post/kickoff-meetup-dplyr-demo/</link>
      <pubDate>Mon, 08 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/kickoff-meetup-dplyr-demo/</guid>
      <description>This is an R script ported from here.
# Load packages library(&amp;quot;dplyr&amp;quot;) library(&amp;quot;ggplot2&amp;quot;) library(&amp;quot;nycflights13&amp;quot;) library(&amp;quot;lubridate&amp;quot;) # it&amp;#39;s a data.frame, but also a tbl_df. # doesn&amp;#39;t print entire thing to screen. flights ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # .</description>
    </item>
    
    <item>
      <title>texreg: converting model output to Latex or HTML</title>
      <link>/post/texreg-converting-model-output-to-latex-or-html/</link>
      <pubDate>Fri, 25 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/texreg-converting-model-output-to-latex-or-html/</guid>
      <description>In the first example we use college admissions data to model gpa as a function of class rank, act score and year of admission. Three linear models are fit and summarized in a single table using the texreg functions screenreg, texreg and htmlreg. These functions create nicely formatted tables for the R console, LaTeX, and HTML, respectively. The second example uses NRC Data on research-doctorate programs to do beta regressions of PhD completion rates on Faculty Publications, Citation Rate, Faculty Grants and Institution type.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>/contact/</link>
      <pubDate>Wed, 09 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/contact/</guid>
      <description> First Name  Last Name  E-Mail  City  State AL CA IL      Send   </description>
    </item>
    
  </channel>
</rss>